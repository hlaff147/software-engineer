{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä An√°lise de Load Test - Azure Service Bus PoC\n",
    "\n",
    "Este notebook analisa os resultados dos testes de carga comparando:\n",
    "- **Bad Producer**: Cria nova conex√£o a cada request (e nunca fecha!)\n",
    "- **Good Producer**: Reutiliza uma √∫nica conex√£o\n",
    "\n",
    "## M√©tricas Analisadas:\n",
    "- Lat√™ncia de resposta\n",
    "- Throughput (requests/seg)\n",
    "- Taxa de erros\n",
    "- Conex√µes vazadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Cores para os gr√°ficos\n",
    "BAD_COLOR = '#e74c3c'  # Vermelho\n",
    "GOOD_COLOR = '#27ae60'  # Verde\n",
    "\n",
    "print('‚úÖ Bibliotecas carregadas!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar Resultados dos Testes k6\n",
    "\n",
    "O k6 gera dois tipos de arquivos:\n",
    "- `*_raw.json` - NDJSON (cada linha √© um evento) - N√ÉO USAR\n",
    "- `*_<timestamp>.json` - JSON de resumo com m√©tricas agregadas - USAR ESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para carregar o arquivo de resumo k6 (exclui arquivos *_raw.json)\n",
    "def load_latest_k6_summary(producer_type):\n",
    "    \"\"\"Carrega o arquivo de resumo k6 mais recente para um tipo de producer.\n",
    "    \n",
    "    Args:\n",
    "        producer_type: 'bad_producer' ou 'good_producer'\n",
    "    \"\"\"\n",
    "    # Buscar arquivos com timestamp (excluir _raw.json)\n",
    "    all_files = glob.glob(f'results/{producer_type}_*.json')\n",
    "    summary_files = [f for f in all_files if '_raw.json' not in f]\n",
    "    \n",
    "    if not summary_files:\n",
    "        print(f'‚ö†Ô∏è Nenhum arquivo de resumo encontrado para: {producer_type}')\n",
    "        return None\n",
    "    \n",
    "    latest_file = sorted(summary_files)[-1]\n",
    "    print(f'üìÇ Carregando: {latest_file}')\n",
    "    \n",
    "    with open(latest_file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Carregar resultados\n",
    "bad_producer_results = load_latest_k6_summary('bad_producer')\n",
    "good_producer_results = load_latest_k6_summary('good_producer')\n",
    "\n",
    "if bad_producer_results:\n",
    "    print(f\"\\nüìä Bad Producer: {bad_producer_results.get('metrics', {}).get('http_reqs', {}).get('values', {}).get('count', 0)} requests\")\n",
    "if good_producer_results:\n",
    "    print(f\"üìä Good Producer: {good_producer_results.get('metrics', {}).get('http_reqs', {}).get('values', {}).get('count', 0)} requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para extrair m√©tricas do resultado k6\n",
    "def extract_k6_metrics(result):\n",
    "    if not result:\n",
    "        return None\n",
    "    \n",
    "    metrics = result.get('metrics', {})\n",
    "    \n",
    "    # Extrair valores com tratamento para chaves que podem n√£o existir\n",
    "    http_reqs = metrics.get('http_reqs', {}).get('values', {})\n",
    "    http_duration = metrics.get('http_req_duration', {}).get('values', {})\n",
    "    http_failed = metrics.get('http_req_failed', {}).get('values', {})\n",
    "    leaked = metrics.get('leaked_connections', {}).get('values', {})\n",
    "    success = metrics.get('success_rate', {}).get('values', {})\n",
    "    \n",
    "    return {\n",
    "        'total_requests': http_reqs.get('count', 0),\n",
    "        'rps': http_reqs.get('rate', 0),\n",
    "        'avg_latency_ms': http_duration.get('avg', 0),\n",
    "        'p50_latency_ms': http_duration.get('med', 0),\n",
    "        'p90_latency_ms': http_duration.get('p(90)', 0),\n",
    "        'p95_latency_ms': http_duration.get('p(95)', 0),\n",
    "        'min_latency_ms': http_duration.get('min', 0),\n",
    "        'max_latency_ms': http_duration.get('max', 0),\n",
    "        'failure_rate': http_failed.get('rate', 0),\n",
    "        'leaked_connections': leaked.get('count', 0),\n",
    "        'success_rate': success.get('rate', 0),\n",
    "    }\n",
    "\n",
    "bad_metrics = extract_k6_metrics(bad_producer_results)\n",
    "good_metrics = extract_k6_metrics(good_producer_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           üìä M√âTRICAS EXTRA√çDAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if bad_metrics:\n",
    "    print(f\"\\n‚ò†Ô∏è BAD PRODUCER:\")\n",
    "    for key, value in bad_metrics.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "if good_metrics:\n",
    "    print(f\"\\n‚úÖ GOOD PRODUCER:\")\n",
    "    for key, value in good_metrics.items():\n",
    "        print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tabela Comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bad_metrics and good_metrics:\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'M√©trica': [\n",
    "            'Total de Requests',\n",
    "            'Requests/segundo',\n",
    "            'Lat√™ncia M√©dia (ms)',\n",
    "            'Lat√™ncia p50 (ms)',\n",
    "            'Lat√™ncia p90 (ms)',\n",
    "            'Lat√™ncia p95 (ms)',\n",
    "            'Lat√™ncia M√°xima (ms)',\n",
    "            'Taxa de Falhas (%)',\n",
    "            'Taxa de Sucesso (%)',\n",
    "            'Conex√µes Vazadas'\n",
    "        ],\n",
    "        'Bad Producer ‚ò†Ô∏è': [\n",
    "            bad_metrics['total_requests'],\n",
    "            f\"{bad_metrics['rps']:.3f}\",\n",
    "            f\"{bad_metrics['avg_latency_ms']:.2f}\",\n",
    "            f\"{bad_metrics['p50_latency_ms']:.2f}\",\n",
    "            f\"{bad_metrics['p90_latency_ms']:.2f}\",\n",
    "            f\"{bad_metrics['p95_latency_ms']:.2f}\",\n",
    "            f\"{bad_metrics['max_latency_ms']:.2f}\",\n",
    "            f\"{bad_metrics['failure_rate']*100:.1f}\",\n",
    "            f\"{bad_metrics['success_rate']*100:.1f}\",\n",
    "            bad_metrics['leaked_connections']\n",
    "        ],\n",
    "        'Good Producer ‚úÖ': [\n",
    "            good_metrics['total_requests'],\n",
    "            f\"{good_metrics['rps']:.3f}\",\n",
    "            f\"{good_metrics['avg_latency_ms']:.2f}\",\n",
    "            f\"{good_metrics['p50_latency_ms']:.2f}\",\n",
    "            f\"{good_metrics['p90_latency_ms']:.2f}\",\n",
    "            f\"{good_metrics['p95_latency_ms']:.2f}\",\n",
    "            f\"{good_metrics['max_latency_ms']:.2f}\",\n",
    "            f\"{good_metrics['failure_rate']*100:.1f}\",\n",
    "            f\"{good_metrics['success_rate']*100:.1f}\",\n",
    "            good_metrics['leaked_connections']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print('\\nüìä COMPARA√á√ÉO DE RESULTADOS K6\\n')\n",
    "    display(comparison_df)\n",
    "else:\n",
    "    print('‚ö†Ô∏è Execute os testes k6 primeiro para gerar dados!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gr√°fico de Lat√™ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bad_metrics and good_metrics:\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    x = np.arange(4)\n",
    "    width = 0.35\n",
    "    \n",
    "    bad_values = [\n",
    "        bad_metrics['avg_latency_ms'],\n",
    "        bad_metrics['p50_latency_ms'],\n",
    "        bad_metrics['p90_latency_ms'],\n",
    "        bad_metrics['max_latency_ms']\n",
    "    ]\n",
    "    \n",
    "    good_values = [\n",
    "        good_metrics['avg_latency_ms'],\n",
    "        good_metrics['p50_latency_ms'],\n",
    "        good_metrics['p90_latency_ms'],\n",
    "        good_metrics['max_latency_ms']\n",
    "    ]\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, bad_values, width, label='Bad Producer ‚ò†Ô∏è', color=BAD_COLOR)\n",
    "    bars2 = ax.bar(x + width/2, good_values, width, label='Good Producer ‚úÖ', color=GOOD_COLOR)\n",
    "    \n",
    "    ax.set_xlabel('M√©trica de Lat√™ncia', fontsize=12)\n",
    "    ax.set_ylabel('Tempo (ms)', fontsize=12)\n",
    "    ax.set_title('üìä Compara√ß√£o de Lat√™ncia: Bad vs Good Producer', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['M√©dia', 'p50', 'p90', 'M√°ximo'])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.0f}ms',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.0f}ms',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/latency_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('üíæ Gr√°fico salvo em: results/latency_comparison.png')\n",
    "else:\n",
    "    print('‚ö†Ô∏è Dados n√£o dispon√≠veis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gr√°fico de Taxa de Sucesso vs Falha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bad_metrics and good_metrics:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bad Producer\n",
    "    bad_success = bad_metrics['success_rate'] * 100\n",
    "    bad_fail = bad_metrics['failure_rate'] * 100\n",
    "    axes[0].pie([bad_success, bad_fail], labels=['Sucesso', 'Falha'], \n",
    "                colors=[GOOD_COLOR, BAD_COLOR], autopct='%1.1f%%',\n",
    "                explode=(0, 0.1), shadow=True)\n",
    "    axes[0].set_title(f'‚ò†Ô∏è BAD PRODUCER\\n{bad_metrics[\"total_requests\"]} requests', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Good Producer\n",
    "    good_success = good_metrics['success_rate'] * 100\n",
    "    good_fail = good_metrics['failure_rate'] * 100\n",
    "    axes[1].pie([good_success, good_fail], labels=['Sucesso', 'Falha'], \n",
    "                colors=[GOOD_COLOR, BAD_COLOR], autopct='%1.1f%%',\n",
    "                explode=(0, 0.1), shadow=True)\n",
    "    axes[1].set_title(f'‚úÖ GOOD PRODUCER\\n{good_metrics[\"total_requests\"]} requests', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/success_rate_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('üíæ Gr√°fico salvo em: results/success_rate_comparison.png')\n",
    "else:\n",
    "    print('‚ö†Ô∏è Dados n√£o dispon√≠veis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conex√µes Vazadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bad_metrics and bad_metrics['leaked_connections'] > 0:\n",
    "    leaked = bad_metrics['leaked_connections']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    categories = ['Conex√µes\\nVazadas', 'Mem√≥ria\\nEstimada (MB)', 'Threads\\nExtras']\n",
    "    values = [leaked, leaked * 2, leaked * 3]\n",
    "    colors = [BAD_COLOR, '#e67e22', '#9b59b6']\n",
    "    \n",
    "    bars = ax.bar(categories, values, color=colors, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax.set_ylabel('Quantidade', fontsize=12)\n",
    "    ax.set_title('‚ò†Ô∏è IMPACTO DO RESOURCE LEAK - Bad Producer', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Adicionar valores\n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.annotate(f'{val:.0f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                    xytext=(0, 5),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/resource_leak_impact.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'\\n‚ò†Ô∏è IMPACTO DO VAZAMENTO:')\n",
    "    print(f'   ‚Ä¢ Conex√µes nunca fechadas: {leaked}')\n",
    "    print(f'   ‚Ä¢ Mem√≥ria vazada estimada: ~{leaked * 2} MB')\n",
    "    print(f'   ‚Ä¢ Threads extras criadas: ~{leaked * 3}')\n",
    "else:\n",
    "    print('‚ÑπÔ∏è Nenhuma conex√£o vazada registrada (ou dados n√£o dispon√≠veis)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resumo e Conclus√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚ïê' * 70)\n",
    "print('                    üìä RESUMO DA AN√ÅLISE')\n",
    "print('‚ïê' * 70)\n",
    "\n",
    "if bad_metrics and good_metrics:\n",
    "    print('\\nüî¥ BAD PRODUCER (Anti-pattern):')\n",
    "    print(f'   ‚Ä¢ Cria NOVA conex√£o a cada request')\n",
    "    print(f'   ‚Ä¢ NUNCA fecha as conex√µes')\n",
    "    print(f'   ‚Ä¢ Total requests: {bad_metrics[\"total_requests\"]}')\n",
    "    print(f'   ‚Ä¢ Lat√™ncia m√©dia: {bad_metrics[\"avg_latency_ms\"]:.2f}ms')\n",
    "    print(f'   ‚Ä¢ Taxa de falhas: {bad_metrics[\"failure_rate\"]*100:.1f}%')\n",
    "    print(f'   ‚Ä¢ Conex√µes vazadas: {bad_metrics[\"leaked_connections\"]}')\n",
    "    \n",
    "    print('\\nüü¢ GOOD PRODUCER (Best Practice):')\n",
    "    print(f'   ‚Ä¢ Reutiliza UMA √öNICA conex√£o')\n",
    "    print(f'   ‚Ä¢ Gerenciada pelo Spring Container')\n",
    "    print(f'   ‚Ä¢ Total requests: {good_metrics[\"total_requests\"]}')\n",
    "    print(f'   ‚Ä¢ Lat√™ncia m√©dia: {good_metrics[\"avg_latency_ms\"]:.2f}ms')\n",
    "    print(f'   ‚Ä¢ Taxa de falhas: {good_metrics[\"failure_rate\"]*100:.1f}%')\n",
    "    \n",
    "    print('\\nüìà COMPARA√á√ÉO:')\n",
    "    if bad_metrics['avg_latency_ms'] > 0 and good_metrics['avg_latency_ms'] > 0:\n",
    "        if bad_metrics['avg_latency_ms'] > good_metrics['avg_latency_ms']:\n",
    "            improvement = ((bad_metrics['avg_latency_ms'] - good_metrics['avg_latency_ms']) \n",
    "                          / bad_metrics['avg_latency_ms'] * 100)\n",
    "            print(f'   ‚Ä¢ Good Producer √© {improvement:.1f}% mais r√°pido')\n",
    "        else:\n",
    "            # No emulador lento, bad producer pode parecer \"mais r√°pido\" por criar conex√µes paralelas\n",
    "            print(f'   ‚Ä¢ ‚ö†Ô∏è No emulador lento, bad producer criou mais conex√µes paralelas')\n",
    "    \n",
    "    if bad_metrics['leaked_connections'] > 0:\n",
    "        print(f'\\n‚ò†Ô∏è IMPACTO DO RESOURCE LEAK:')\n",
    "        print(f'   ‚Ä¢ {bad_metrics[\"leaked_connections\"]} conex√µes nunca fechadas')\n",
    "        print(f'   ‚Ä¢ Em produ√ß√£o, isso causaria OutOfMemoryError!')\n",
    "\n",
    "print('\\n' + '‚ïê' * 70)\n",
    "print('\\n‚úÖ CONCLUS√ÉO: Sempre use conex√µes gerenciadas pelo Spring Container!')\n",
    "print('   Evite criar ServiceBusSenderClient manualmente em cada request.')\n",
    "print('\\n‚ö†Ô∏è NOTA: O emulador local √© muito mais lento que o Azure real.')\n",
    "print('   Em produ√ß√£o, a diferen√ßa de performance seria muito maior!')\n",
    "print('‚ïê' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
