# ðŸŽ“ AI Engineer Study Guide

> A comprehensive study documentation covering AI agent architectures, design patterns, and engineering insights learned from building real-world AI systems.

---

## Table of Contents

1. [Introduction](#introduction)
2. [AI Agent Fundamentals](#ai-agent-fundamentals)
3. [Architecture Patterns](#architecture-patterns)
4. [Design Principles](#design-principles)
5. [Implementation Insights](#implementation-insights)
6. [Tools & Frameworks](#tools--frameworks)
7. [Best Practices](#best-practices)
8. [Common Pitfalls](#common-pitfalls)
9. [Future Directions](#future-directions)

---

## Introduction

### What is an AI Engineer?

An **AI Engineer** bridges the gap between AI research and production systems. Unlike ML Engineers who focus on model training, AI Engineers specialize in:

- **Orchestrating AI systems** - Combining multiple models and tools
- **Building agentic systems** - Creating autonomous AI that can reason and act
- **Prompt engineering** - Designing effective prompts for LLMs
- **System integration** - Connecting AI to real-world APIs and data sources

### The Agentic AI Paradigm Shift

```
Traditional AI:   Input â†’ Model â†’ Output (single pass)

Agentic AI:       Input â†’ Plan â†’ Execute â†’ Observe â†’ Reflect â†’ Iterate â†’ Output
                           â†‘__________________________________|
```

Modern AI systems don't just predictâ€”they **reason**, **plan**, and **act**.

---

## AI Agent Fundamentals

### What is an AI Agent?

An AI agent is an autonomous system that:
1. **Perceives** its environment (receives inputs)
2. **Reasons** about the situation (uses LLM/logic)
3. **Acts** to achieve goals (calls tools, APIs)
4. **Learns** from outcomes (adjusts behavior)

### Agent Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI AGENT                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   MEMORY    â”‚  â”‚   PLANNER   â”‚  â”‚   TOOLS     â”‚     â”‚
â”‚  â”‚ (context)   â”‚  â”‚  (LLM/logic)â”‚  â”‚  (actions)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                â”‚                â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                          â”‚                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                        â”‚
â”‚                    â”‚ EXECUTOR  â”‚                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Agent Loop

Every agent follows a fundamental loop:

```python
while not goal_achieved:
    observation = perceive(environment)
    thought = reason(observation, memory)
    action = decide(thought)
    result = execute(action)
    memory.update(result)
```

---

## Architecture Patterns

### Pattern Catalog

| # | Pattern | Core Concept | Best For |
|---|---------|--------------|----------|
| 01 | Reflection | Self-critique and refinement | Quality-critical outputs |
| 02 | Tool Use | External API integration | Real-time data access |
| 03 | ReAct | Reason + Act loop | Multi-step problem solving |
| 04 | Planning | Decompose before executing | Complex structured tasks |
| 05 | Multi-Agent | Specialized collaborating agents | Large complex systems |
| 06 | PEV | Plan, Execute, Verify | High-stakes automation |
| 07 | Blackboard | Shared memory coordination | Dynamic collaboration |
| 08 | Dual Memory | Episodic + Semantic memory | Personalized assistants |
| 09 | Tree of Thoughts | Branching exploration | Logic puzzles |
| 10 | Mental Loop | Simulate before acting | Safety-critical systems |
| 11 | Meta-Controller | Intelligent routing | Multi-service platforms |
| 12 | Graph Memory | Knowledge graph storage | Complex reasoning |
| 13 | Ensemble | Multiple perspectives | Reducing bias |
| 14 | Dry-Run | Simulate then approve | Production safety |
| 15 | RLHF Loop | Feedback-driven improvement | Content generation |
| 16 | Cellular Automata | Emergent behavior | Spatial problems |
| 17 | Metacognitive | Self-aware limitations | High-stakes advisory |

---

### Pattern 1: Reflection

**Concept:** Move from single-pass generation to iterative self-improvement.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GENERATE â”‚â”€â”€â”€â”€â–¶â”‚ CRITIQUE â”‚â”€â”€â”€â”€â–¶â”‚  REFINE  â”‚â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
      â–²                                          â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    (iterate until good)
```

**Implementation:**
```python
def reflect(initial_output):
    critique = llm.invoke(f"Critique this: {initial_output}")
    refined = llm.invoke(f"Improve based on: {critique}")
    return refined
```

**When to use:**
- Code generation requiring correctness
- Report writing requiring quality
- Any task where "good enough" isn't good enough

---

### Pattern 2: Tool Use

**Concept:** Extend LLM capabilities with external tools.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM   â”‚â”€â”€â”€â”€â–¶â”‚ TOOL ROUTER â”‚â”€â”€â”€â”€â–¶â”‚  TOOLS  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â–¼                  â–¼                  â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  Search   â”‚      â”‚ Calculatorâ”‚      â”‚    API    â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**
```python
@tool
def search_web(query: str) -> str:
    """Search the web for information."""
    return duckduckgo_search(query)

agent = create_react_agent(llm, tools=[search_web])
```

**When to use:**
- Real-time information needs
- Mathematical calculations
- External system integration

---

### Pattern 3: ReAct (Reason + Act)

**Concept:** Interleave thinking and acting in a dynamic loop.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ReAct Loop                 â”‚
â”‚                                             â”‚
â”‚  Thought: "I need to find the stock price"  â”‚
â”‚      â†“                                      â”‚
â”‚  Action: search("AAPL stock price")         â”‚
â”‚      â†“                                      â”‚
â”‚  Observation: "$195.50"                     â”‚
â”‚      â†“                                      â”‚
â”‚  Thought: "Now I need to analyze..."        â”‚
â”‚      â†“                                      â”‚
â”‚  (continue until done)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**
```python
REACT_PROMPT = """
Thought: {think about what to do}
Action: {tool_name}[{tool_input}]
Observation: {result}
... (repeat)
Final Answer: {answer}
"""
```

**When to use:**
- Multi-step research tasks
- Web navigation
- Complex Q&A requiring multiple sources

---

### Pattern 4: Planning

**Concept:** Create a full plan before executing any steps.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PLANNER                     â”‚
â”‚                                             â”‚
â”‚  Task: "Analyze AAPL stock"                 â”‚
â”‚                                             â”‚
â”‚  Plan:                                      â”‚
â”‚  1. Fetch current price data                â”‚
â”‚  2. Calculate technical indicators          â”‚
â”‚  3. Search for recent news                  â”‚
â”‚  4. Analyze sentiment                       â”‚
â”‚  5. Generate recommendation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    EXECUTOR    â”‚ (follows plan step by step)
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When to use:**
- Predictable, structured workflows
- When steps are known upfront
- Report generation, project management

---

### Pattern 5: Multi-Agent Systems

**Concept:** Specialized agents collaborate on complex tasks.

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  SUPERVISOR  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                 â–¼                 â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ RESEARCHERâ”‚    â”‚  WRITER   â”‚    â”‚  EDITOR   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation (LangGraph):**
```python
workflow = StateGraph(AgentState)
workflow.add_node("Researcher", researcher_node)
workflow.add_node("Writer", writer_node)
workflow.add_node("Editor", editor_node)
workflow.add_edge("Researcher", "Writer")
workflow.add_edge("Writer", "Editor")
```

**When to use:**
- Complex tasks requiring different expertise
- Software development pipelines
- Content creation workflows

---

### Pattern 6: PEV (Plan, Execute, Verify)

**Concept:** Add verification after execution with retry capability.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PLAN   â”‚â”€â”€â”€â”€â–¶â”‚ EXECUTE  â”‚â”€â”€â”€â”€â–¶â”‚  VERIFY  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â–²               â”‚
                       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚    â”‚                     â”‚
                       â”‚   âŒ FAIL               âœ… PASS
                       â”‚    â”‚                     â”‚
                       â””â”€â”€â”€â”€â”˜                     â–¼
                    (retry)                    OUTPUT
```

**Implementation:**
```python
def pev_loop(task, max_retries=3):
    plan = planner.create_plan(task)
    
    for attempt in range(max_retries):
        result = executor.execute(plan)
        verification = verifier.check(result)
        
        if verification.passed:
            return result
        
        # Feed verification feedback to executor
        plan = planner.revise(plan, verification.issues)
    
    return result  # Return best effort after max retries
```

**When to use:**
- Financial systems (incorrect recommendations are costly)
- Medical/legal applications
- Any high-stakes automation

---

### Pattern 11: Meta-Controller

**Concept:** Intelligent routing to specialized sub-agents.

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  META-CONTROLLER â”‚
                    â”‚   "What type of  â”‚
                    â”‚    task is this?"â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CODE AGENT  â”‚       â”‚ MATH AGENT  â”‚       â”‚ WRITE AGENT â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**
```python
ROUTER_PROMPT = """
Analyze the user's request and route to the appropriate agent:
- "code": For programming tasks
- "math": For calculations
- "write": For content creation

Request: {user_input}
Route to: 
"""

def route(state):
    decision = llm.invoke(ROUTER_PROMPT.format(user_input=state["input"]))
    return {"next": decision.strip()}
```

**When to use:**
- Multi-purpose AI assistants
- Enterprise bots with multiple capabilities
- Reducing latency by avoiding unnecessary agents

---

### Pattern 13: Ensemble

**Concept:** Multiple agents analyze independently, then aggregate.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INPUT TASK                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONSERVATIVEâ”‚ â”‚  BALANCED   â”‚ â”‚ AGGRESSIVE  â”‚
â”‚   ANALYST   â”‚ â”‚   ANALYST   â”‚ â”‚   ANALYST   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚               â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  AGGREGATOR    â”‚
              â”‚ "Synthesize    â”‚
              â”‚  all views"    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When to use:**
- Reducing bias in recommendations
- High-stakes decision support
- Fact-checking and verification

---

## Design Principles

### 1. State-First Design

Always design your state schema before building agents.

```python
class AgentState(TypedDict):
    messages: List[BaseMessage]      # Conversation history
    next: str                         # Routing decision
    current_data: dict               # Working memory
    iteration_count: int             # Loop guard
    verification_passed: bool        # Quality gate
```

### 2. Separation of Concerns

Each agent should have a single responsibility:

| âŒ Bad | âœ… Good |
|--------|---------|
| `general_agent()` | `researcher_agent()` |
| does everything | `analyst_agent()` |
| hard to debug | `verifier_agent()` |

### 3. Fail Gracefully

```python
def agent_node(state):
    try:
        result = process(state)
        return {"status": "success", "data": result}
    except Exception as e:
        logger.error(f"Agent failed: {e}")
        return {"status": "error", "message": str(e)}
        # Don't crash the entire workflow
```

### 4. Limit Iterations

Always guard against infinite loops:

```python
MAX_ITERATIONS = 10

def should_continue(state):
    if state["iteration_count"] >= MAX_ITERATIONS:
        return "FINISH"  # Force exit
    return state["next"]
```

### 5. Structured Outputs

Force LLMs to output structured data:

```python
PROMPT = """
Respond with JSON only:
{"recommendation": "BUY|SELL|HOLD", "confidence": 0-100}
"""

# Or use Pydantic
class Recommendation(BaseModel):
    action: Literal["BUY", "SELL", "HOLD"]
    confidence: int = Field(ge=0, le=100)
```

---

## Implementation Insights

### Insight 1: LLMs are Poor at Arithmetic

**Problem:** LLMs hallucinate calculations.

**Solution:** Use tools for any math:
```python
@tool
def calculate_rsi(prices: list) -> float:
    """Calculate RSI from price data."""
    # Actual calculation, not LLM guessing
    delta = pd.Series(prices).diff()
    gain = delta.where(delta > 0, 0).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    return 100 - (100 / (1 + gain.iloc[-1] / loss.iloc[-1]))
```

### Insight 2: Prompt Engineering is Critical

**Before (vague):**
```
"Analyze this stock and give a recommendation."
```

**After (structured):**
```
You are a senior portfolio manager.

Analyze {ticker} using the provided data:
{technical_data}

Structure your response as:
1. Executive Summary (1 paragraph)
2. Technical Analysis
3. Recommendation: BUY / SELL / HOLD
4. Risk Level: High / Medium / Low
```

### Insight 3: Message History Management

Don't send the entire historyâ€”LLMs have context limits:

```python
def get_recent_context(messages, limit=10):
    """Get last N messages to stay within context window."""
    return messages[-limit:]
```

### Insight 4: Temperature Matters

| Task | Temperature | Why |
|------|-------------|-----|
| Routing/JSON | 0.0 | Deterministic output needed |
| Analysis | 0.3-0.5 | Some creativity, mostly factual |
| Creative writing | 0.7-0.9 | High creativity |

### Insight 5: Verification Catches Hallucinations

Real example from our Hedge Fund Bot:

```
âŒ Analyst said: "RSI is 45 (oversold)"
âœ… Verifier caught: "RSI 45 is neutral, not oversold. Oversold is < 30"
```

---

## Tools & Frameworks

### LangChain Ecosystem

| Tool | Purpose |
|------|---------|
| **LangChain** | LLM abstraction, tools, chains |
| **LangGraph** | Stateful multi-agent workflows |
| **LangSmith** | Tracing, debugging, evaluation |

### LangGraph Basics

```python
from langgraph.graph import StateGraph, END

# 1. Define state
class State(TypedDict):
    messages: list
    next: str

# 2. Create graph
workflow = StateGraph(State)

# 3. Add nodes (agents)
workflow.add_node("agent_a", agent_a_function)
workflow.add_node("agent_b", agent_b_function)

# 4. Add edges (flow)
workflow.add_edge("agent_a", "agent_b")
workflow.add_conditional_edges("agent_b", router_function, {...})

# 5. Set entry point
workflow.set_entry_point("agent_a")

# 6. Compile and run
app = workflow.compile()
result = app.invoke(initial_state)
```

### Recommended Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     APPLICATION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Orchestration:  LangGraph                              â”‚
â”‚  LLM Provider:   Groq (Llama 3), OpenAI, Anthropic     â”‚
â”‚  Tools:          yfinance, DuckDuckGo, custom APIs     â”‚
â”‚  Vector Store:   Pinecone, Chroma, FAISS               â”‚
â”‚  Observability:  LangSmith, Weights & Biases           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Best Practices

### 1. Start Simple, Add Complexity

```
Week 1: Single agent with tools
Week 2: Add supervisor for routing
Week 3: Add verification layer
Week 4: Add multiple specialized agents
```

### 2. Log Everything

```python
import logging

logger = logging.getLogger(__name__)

def agent_node(state):
    logger.info(f"Agent invoked with: {state['current_ticker']}")
    result = process(state)
    logger.info(f"Agent output: {result.get('recommendation')}")
    return result
```

### 3. Use Type Hints

```python
from typing import TypedDict, Annotated, List
from langchain_core.messages import BaseMessage
import operator

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]  # Append-only
    next: str
```

### 4. Test Agents Individually

```python
def test_researcher_agent():
    state = {"current_ticker": "AAPL", "messages": []}
    result = researcher_node(state)
    
    assert "[RESEARCHER" in result["messages"][0].content
    assert "AAPL" in result["messages"][0].content
```

### 5. Document Agent Responsibilities

```python
"""
Researcher Agent
================

Purpose: Gather fundamental data (news, sentiment)

Inputs:
- current_ticker: Stock symbol to research

Outputs:
- messages: Research summary appended

Tools Used:
- search_financial_news()
- search_market_sentiment()
"""
```

---

## Common Pitfalls

### âŒ Pitfall 1: Infinite Loops

```python
# BAD: No exit condition
workflow.add_edge("agent", "agent")

# GOOD: Guard with counter
def should_continue(state):
    if state["iteration_count"] > 10:
        return "FINISH"
    return state["next"]
```

### âŒ Pitfall 2: Context Window Overflow

```python
# BAD: Sending all history
context = "\n".join([m.content for m in messages])

# GOOD: Limit context
context = "\n".join([m.content[:200] for m in messages[-5:]])
```

### âŒ Pitfall 3: Trusting LLM JSON Output

```python
# BAD: Assuming valid JSON
result = json.loads(response.content)

# GOOD: Handle parsing errors
try:
    if "```" in text:
        text = text.split("```")[1].replace("json", "").strip()
    result = json.loads(text)
except json.JSONDecodeError:
    result = {"next": "FINISH"}  # Fallback
```

### âŒ Pitfall 4: No Verification

```python
# BAD: Trust agent output directly
return analyst_output

# GOOD: Verify before returning
verification = verifier.check(analyst_output)
if not verification.passed:
    return retry_analyst(feedback=verification.issues)
return analyst_output
```

### âŒ Pitfall 5: Hardcoded Prompts

```python
# BAD: Prompts buried in code
response = llm.invoke("Analyze the stock...")

# GOOD: Externalized, versioned prompts
ANALYST_PROMPT = """
Version: 1.2
Role: Senior Portfolio Manager
...
"""
```

---

## Future Directions

### Emerging Patterns

1. **Autonomous Agents** - Agents that run continuously (AutoGPT-style)
2. **Agent-to-Agent Communication** - Direct agent messaging (not via supervisor)
3. **Learning Agents** - Agents that improve from feedback over time
4. **Hierarchical Teams** - Teams of teams for enterprise scale

### Key Technologies to Watch

| Technology | What it Enables |
|------------|-----------------|
| **Claude 3.5 / GPT-5** | Better reasoning, longer context |
| **LangGraph Cloud** | Hosted agent deployments |
| **Function Calling v2** | More reliable tool use |
| **Agent Protocols** | Standardized agent communication |

### Recommended Learning Path

```
1. Build a simple chatbot with tools
2. Add multi-step reasoning (ReAct)
3. Create multi-agent system
4. Add verification layer (PEV)
5. Implement memory systems
6. Deploy to production with observability
```

---

## Quick Reference

### Pattern Selection Guide

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           WHICH PATTERN SHOULD I USE?                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Need real-time data?                                   â”‚
â”‚  â””â”€â”€ Yes â”€â”€â–¶ Tool Use (#02)                            â”‚
â”‚                                                         â”‚
â”‚  Complex task with multiple expertise areas?            â”‚
â”‚  â””â”€â”€ Yes â”€â”€â–¶ Multi-Agent (#05)                         â”‚
â”‚                                                         â”‚
â”‚  Need high accuracy / self-correction?                  â”‚
â”‚  â””â”€â”€ Yes â”€â”€â–¶ PEV (#06) or Reflection (#01)             â”‚
â”‚                                                         â”‚
â”‚  Multiple valid approaches to explore?                  â”‚
â”‚  â””â”€â”€ Yes â”€â”€â–¶ Tree of Thoughts (#09)                    â”‚
â”‚                                                         â”‚
â”‚  High-stakes / safety-critical?                         â”‚
â”‚  â””â”€â”€ Yes â”€â”€â–¶ Dry-Run (#14) + Metacognitive (#17)       â”‚
â”‚                                                         â”‚
â”‚  Need to reduce bias?                                   â”‚
â”‚  â””â”€â”€ Yes â”€â”€â–¶ Ensemble (#13)                            â”‚
â”‚                                                         â”‚
â”‚  Routing to specialists?                                â”‚
â”‚  â””â”€â”€ Yes â”€â”€â–¶ Meta-Controller (#11)                     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Essential Code Snippets

**Create a tool:**
```python
from langchain_core.tools import tool

@tool
def my_tool(input: str) -> str:
    """Tool description for the LLM."""
    return process(input)
```

**Create a node:**
```python
def my_node(state: AgentState) -> dict:
    result = process(state)
    return {"messages": [HumanMessage(content=result)]}
```

**Conditional routing:**
```python
workflow.add_conditional_edges(
    "supervisor",
    lambda x: x["next"],
    {"agent_a": "agent_a", "agent_b": "agent_b", "FINISH": END}
)
```

---

## Resources

### Documentation
- [LangChain Docs](https://python.langchain.com/docs/)
- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)
- [Groq API](https://console.groq.com/docs/quickstart)

### Papers
- [ReAct: Synergizing Reasoning and Acting](https://arxiv.org/abs/2210.03629)
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761)
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)

### Courses
- [DeepLearning.AI - Building AI Agents with LangGraph](https://www.deeplearning.ai/)
- [LangChain Academy](https://academy.langchain.com/)

---

## Project Index

| Project | Patterns Used | Documentation |
|---------|---------------|---------------|
| [Hedge Fund Bot](./hedge_fund_bot/) | Tool Use, Multi-Agent, PEV, Meta-Controller | [Patterns Doc](./hedge_fund_bot/docs/PATTERNS.md) |

---

*Last updated: December 2024*

*"The best AI systems are not single models, but orchestrated ensembles of specialized agents working together."*
